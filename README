## λ refactor to improve security and reduce latency

- started 11/25/24
- Improving Security by Placing λ Functions in a VPC
  - Placing your λ functions inside a Virtual Private Cloud (VPC) and restricting access via security groups significantly enhances the security of your architecture. Public λ Function URLs expose your backend services to the internet, which increases the risk of unauthorized access or malicious attacks. By moving the λ functions into a VPC, you can apply strict access control through security groups that only allow ingress and egress traffic from your ECS service.
  - This ensures that no other external entities, even those within the VPC but outside the specified security groups, can access the λ functions. This private setup aligns with the principle of least privilege, ensuring that only your Next.js app running in ECS can invoke these λ functions, thereby safeguarding sensitive operations and data.
  - refactored λ to use VPC Endpoint instead of NAT Gateway to communicate with DynamoDB, 11/26/24
    - Using a VPC endpoint for your Lambda functions to access services like DynamoDB is generally cheaper than relying on a NAT gateway. NAT gateways incur both an hourly fee and additional charges for data processing, which can add up significantly if your Lambda functions frequently interact with AWS services.
    - In contrast, VPC endpoints, such as those for DynamoDB, have a flat hourly rate without data processing fees, making them more cost-effective for high-volume usage. Additionally, VPC endpoints enhance security by keeping traffic entirely within the AWS private network and eliminating the need for public IPs or internet routing. While NAT gateways are still necessary for accessing non-AWS services, replacing them with VPC endpoints for AWS-specific interactions can reduce costs and improve both efficiency and security.
- Reducing Latency and Enhancing User Experience
  - Another key advantage of placing your λ functions in a VPC is the reduction of latency. _When λ functions are accessed through public endpoints, requests travel over the internet, introducing delays caused by external routing, network congestion, and TLS handshakes. By contrast, placing the λ functions and ECS service in the same VPC ensures that communication remains internal to AWS’s high-speed private network. This eliminates public internet overhead and optimizes routing, leading to faster response times._
  - For your Next.js app, this translates to reduced latency for API calls, ensuring a smoother and faster user experience. This is especially critical for real-time or latency-sensitive operations where every millisecond counts.
- Integrating API Gateway for URL-Based Access
  - Since your Next.js app running in ECS needs URL endpoints to communicate with the backend, an API Gateway integration is required for the λ functions. By using API Gateway, you can provide a RESTful interface for your app to access the λ functions, but instead of making these endpoints publicly accessible, they can be configured as private APIs. _The API Gateway will also reside within the same VPC, and its security group will be configured to allow access only from the ECS service’s security group._ This ensures that even the API Gateway endpoints are not exposed to the public internet, maintaining the secure, private communication channel. With this setup, your λ functions remain completely private, accessible only through the API Gateway endpoints by the ECS service, ensuring optimal security and performance.
    - Even though your ECS task is running in a public subnet within the same VPC as the API Gateway, a _VPC endpoint is still required because private API Gateways are designed to be accessed only through VPC endpoints or specific VPC peering configurations—they are not directly accessible even from other resources within the same VPC._
    - The VPC endpoint acts as a secure bridge, ensuring that your ECS task can communicate with the private API Gateway while keeping all traffic within the AWS private network. Without the VPC endpoint, your ECS task would not be able to reach the API Gateway’s private APIs, as they are isolated from public and default VPC routes. The VPC endpoint also enhances security by allowing you to restrict access to the private API Gateway based on security group rules, ensuring that only the ECS task can access the API Gateway. This setup maintains a secure and controlled communication channel between your ECS task and the Lambda functions behind the private API Gateway.
- Conclusion
  - Refactoring your architecture to place λ functions in a VPC and restricting access through security groups not only improves security by eliminating public exposure but also reduces latency by keeping communication within AWS’s private network.
  - Integrating API Gateway for λ access ensures that the Next.js app can still use familiar URL endpoints while maintaining a robust, secure, and high-performing backend infrastructure. This approach strengthens your application’s security posture and enhances user experience, making it a necessary and worthwhile improvement to your current setup.

## important things to know

- if you need to update the **LIST OF DRIVERS** (their team, nationality, etc.), you need to do it in these places:
  - `infrastructure/lambda/utils.mjs`
  - `front-end/src/utils/index.js`
- if you need to update the driver scoring system (sprint and race), you need to do it here:
  - `infrastructure/lambda/utils.mjs`

## random notes

- 12/9/24

  - `front-end/Dockerfile`
  - Switching the base images to node:20-alpine helped eliminate the vulnerability because Alpine Linux is a minimalist, security-focused distribution with a significantly smaller attack surface compared to Debian-based images like bullseye. The previously reported vulnerability (SNYK-DEBIAN12-ZLIB-6008963) was introduced through the Debian package zlib, a core library used for compression. By moving to an Alpine-based image, the dependency chain changed, effectively removing the vulnerable version of zlib from the build. Additionally, Alpine’s lean architecture ensures fewer installed packages, reducing the likelihood of vulnerabilities while improving image size and performance. This switch is an example of how tailoring your base image to specific needs can enhance security and efficiency.
  - To address the SNYK-JS-CROSSSPAWN-8303230 vulnerability, we utilized a .snyk policy file to explicitly mark it as ignored during vulnerability scans. This approach allowed us to document that the issue was not exploitable in our specific environment, ensuring transparency and maintaining focus on actionable vulnerabilities. The .snyk file configuration applied the ignore rule globally to all instances of the vulnerability across our dependency chain, along with a detailed reason for ignoring it and an optional expiration date (2025-01-31). This expiration date ensures periodic reevaluation of the vulnerability in case upstream fixes or environment changes occur. By integrating this policy into our workflow, we ensured that scans still provide meaningful results while avoiding unnecessary pipeline failures due to false positives or irrelevant vulnerabilities.

- 12/6/24 - tried to create a new λ for s3 image upload

  - I was trying to integrate my S3 image upload Lambda function behind a private API Gateway endpoint, thinking that since my Next.js application and the gateway were both in the same VPC, everything would just work seamlessly. However, the key detail I overlooked is that the image upload logic in my Next.js app runs in the user’s browser, not on the server. Even though my app’s server-side code can talk to the private gateway inside the VPC, the client-side browser code operates outside of that protected network. As a result, the browser simply can’t reach the private endpoint directly, causing the upload attempt to fail.

- 12/4/24 - ECS auto scaling enabled, check module repo README for more details

- 10/11/24 - since `node_modules` in `infrastructure/lambda` is part of `.gitignore`, `node_modules` were not included in the lambda deployment package zip file when creating them in the workflow - solution was to include `npm install` in the `infrastructure/lambda` as part of the terraform `infrastructure.yaml` workflow - this wasn't an issue before because the other two lambda functions (`app-get.mjs` and `app-post.mjs`) do not rely on non-AWS sdk npm packages - lambda base layers come pre-packaged with the AWS sdks, so you don't need them available to the function within `node_modules`

- 10/11/24 - since runtime environment variables aren't available in client components, did a hacky thing of pulling it in a server component, then passing it as a component prop down to the client component, see `const lambdaPostImageFunctionUrl =
process.env.LAMBDA_POST_IMAGE_FUNCTION_URL ||
"lambdaPostImageFunctionUrl placeholder";` in `front-end/src/app/dashboard/page.js`

- 10/12/24 - had an issue where uploaded images wouldn't load in prod, but worked fine in dev, in prod it was getting 400s (some "url" error in the browser response) when making the same S3 calls being made successfully in dev, turns out, it was Next.js’s built-in Image Optimization API, which modifies the image URL for performance improvements like resizing and quality adjustments. This is why the URL is being rewritten to include /\_next/image?url=.... and the request being made to S3 didn't like this. Since you’re hosting your images on S3, and don’t need Next.js to optimize them (because they’re already optimized or handled elsewhere), you can disable Next.js’s image optimization for those images by marking them as external images. If you only want to disable optimization for certain images, you can use the unoptimized attribute in the Image component to bypass the Image Optimization API, `unoptimized` as a property in the Next.js `Image` component. Maybe this was happening because the Image Optimization API runs in prod but not in dev?

  - see `front-end/src/components/ListInsights.js` for more details, and I also modified `front-end/next.config.mjs` so objects from both directories in the bucket can be fetched

- 10/14/24 - set up cognito, since login component is client, can't get user pool and user pool client ids in runtime - passing in the values at BUILD time, with the ids being stored as action secrets in github UI, see `.github/workflows/front-end.yaml` and `front-end/Dockerfile`
