## λ refactor to improve security and reduce latency

- started 11/25/24
- Improving Security by Placing λ Functions in a VPC
  - Placing your λ functions inside a Virtual Private Cloud (VPC) and restricting access via security groups significantly enhances the security of your architecture. Public λ Function URLs expose your backend services to the internet, which increases the risk of unauthorized access or malicious attacks. By moving the λ functions into a VPC, you can apply strict access control through security groups that only allow ingress and egress traffic from your ECS service. This ensures that no other external entities, even those within the VPC but outside the specified security groups, can access the λ functions. This private setup aligns with the principle of least privilege, ensuring that only your Next.js app running in ECS can invoke these λ functions, thereby safeguarding sensitive operations and data.
- Reducing Latency and Enhancing User Experience
  - Another key advantage of placing your λ functions in a VPC is the reduction of latency. _When λ functions are accessed through public endpoints, requests travel over the internet, introducing delays caused by external routing, network congestion, and TLS handshakes. By contrast, placing the λ functions and ECS service in the same VPC ensures that communication remains internal to AWS’s high-speed private network. This eliminates public internet overhead and optimizes routing, leading to faster response times._ For your Next.js app, this translates to reduced latency for API calls, ensuring a smoother and faster user experience. This is especially critical for real-time or latency-sensitive operations where every millisecond counts.
- Integrating API Gateway for URL-Based Access
  - Since your Next.js app running in ECS needs URL endpoints to communicate with the backend, an API Gateway integration is required for the λ functions. By using API Gateway, you can provide a RESTful interface for your app to access the λ functions, but instead of making these endpoints publicly accessible, they can be configured as private APIs. The API Gateway will also reside within the same VPC, and its security group will be configured to allow access only from the ECS service’s security group. This ensures that even the API Gateway endpoints are not exposed to the public internet, maintaining the secure, private communication channel. With this setup, your λ functions remain completely private, accessible only through the API Gateway endpoints by the ECS service, ensuring optimal security and performance.
- Conclusion
  - Refactoring your architecture to place λ functions in a VPC and restricting access through security groups not only improves security by eliminating public exposure but also reduces latency by keeping communication within AWS’s private network. Integrating API Gateway for λ access ensures that the Next.js app can still use familiar URL endpoints while maintaining a robust, secure, and high-performing backend infrastructure. This approach strengthens your application’s security posture and enhances user experience, making it a necessary and worthwhile improvement to your current setup.

## important things to know

- if you need to update the list of drivers (their team, nationality, etc.), you need to do it in these places:
  - `infrastructure/lambda-test/utils.mjs`
  - `front-end/src/utils/index.js`
- if you need to update the driver scoring system (sprint and race), you need to do it here:
  - `infrastructure/lambda-test/utils.mjs`

## random notes

- 10/11/24 - since `node_modules` in `infrastructure/lambda` is part of `.gitignore`, `node_modules` were not included in the lambda deployment package zip file when creating them in the workflow - solution was to include `npm install` in the `infrastructure/lambda` as part of the terraform `infrastructure.yaml` workflow - this wasn't an issue before because the other two lambda functions (`app-get.mjs` and `app-post.mjs`) do not rely on non-AWS sdk npm packages - lambda base layers come pre-packaged with the AWS sdks, so you don't need them available to the function within `node_modules`

- 10/11/24 - since runtime environment variables aren't available in client components, did a hacky thing of pulling it in a server component, then passing it as a component prop down to the client component, see `const lambdaPostImageFunctionUrl =
process.env.LAMBDA_POST_IMAGE_FUNCTION_URL ||
"lambdaPostImageFunctionUrl placeholder";` in `front-end/src/app/dashboard/page.js`

- 10/12/24 - had an issue where uploaded images wouldn't load in prod, but worked fine in dev, in prod it was getting 400s (some "url" error in the browser response) when making the same S3 calls being made successfully in dev, turns out, it was Next.js’s built-in Image Optimization API, which modifies the image URL for performance improvements like resizing and quality adjustments. This is why the URL is being rewritten to include /\_next/image?url=.... and the request being made to S3 didn't like this. Since you’re hosting your images on S3, and don’t need Next.js to optimize them (because they’re already optimized or handled elsewhere), you can disable Next.js’s image optimization for those images by marking them as external images. If you only want to disable optimization for certain images, you can use the unoptimized attribute in the Image component to bypass the Image Optimization API, `unoptimized` as a property in the Next.js `Image` component. Maybe this was happening because the Image Optimization API runs in prod but not in dev?

  - see `front-end/src/components/ListInsights.js` for more details, and I also modified `front-end/next.config.mjs` so objects from both directories in the bucket can be fetched

- 10/14/24 - set up cognito, since login component is client, can't get user pool and user pool client ids in runtime - passing in the values at BUILD time, with the ids being stored as action secrets in github UI, see `.github/workflows/front-end.yaml` and `front-end/Dockerfile`
